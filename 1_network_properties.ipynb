{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTDS'18 milestone 1: network collection and properties\n",
    "[Effrosyni Simou](https://lts4.epfl.ch/simou), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 31\n",
    "* Students: Dilara Günay, Derin Sinan Bursa, Othman Benchekroun, Sinan Gökçe\n",
    "* Dataset: IMDb Films and Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to three sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this milestone is to start getting acquainted to the network that you will use for this class. In the first part of the milestone you will import your data using [Pandas](http://pandas.pydata.org) and you will create the adjacency matrix using [Numpy](http://www.numpy.org). This part is project specific. In the second part you will have to compute some basic properties of your network. **For the computation of the properties you are only allowed to use the packages that have been imported in the cell below.** You are not allowed to use any graph-specific toolboxes for this milestone (such as networkx and PyGSP). Furthermore, the aim is not to blindly compute the network properties, but to also start to think about what kind of network you will be working with this semester. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Import your data and manipulate them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Load your data in a Panda dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should define and understand what are your nodes, what features you have and what are your labels. Please provide below a Panda dataframe where each row corresponds to a node with its features and labels. For example, in the the case of the Free Music Archive (FMA) Project, each row of the dataframe would be of the following form:\n",
    "\n",
    "\n",
    "| Track   |  Feature 1  | Feature 2 | . . . | Feature 518|  Label 1 |  Label 2 |. . .|Label 16|\n",
    "|:-------:|:-----------:|:---------:|:-----:|:----------:|:--------:|:--------:|:---:|:------:|\n",
    "|         |             |           |       |            |          |          |     |        |\n",
    "\n",
    "It is possible that in some of the projects either the features or the labels are not available. This is OK, in that case just make sure that you create a dataframe where each of the rows corresponds to a node and its associated features or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/tmdb_5000_credits.csv')\n",
    "movies = movies[movies.cast != '[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: In the function below, we only keep the relevant information (<i>movie_id</i> and <i>cast</i> providing us with information on each person). Moreover, we add an important new column: the list of all people playing in a movie, which will be necessary for future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten():\n",
    "    movies.drop(['title', 'crew'], axis=1, inplace=True)\n",
    "    movies['cast_id'] = movies['cast'].apply(lambda row: list(set(pd.read_json(row)['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>cast</th>\n",
       "      <th>cast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...</td>\n",
       "      <td>[397312, 32747, 1207263, 1180936, 1145098, 606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>[{\"cast_id\": 4, \"character\": \"Captain Jack Spa...</td>\n",
       "      <td>[2603, 2440, 2441, 2449, 2450, 2452, 1430, 705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...</td>\n",
       "      <td>[1168129, 578512, 1599254, 1599239, 1437333, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...</td>\n",
       "      <td>[21505, 53252, 1188950, 1172491, 1343746, 7733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"cast_id\": 5, \"character\": \"John Carter\", \"c...</td>\n",
       "      <td>[1721985, 62082, 17287, 1721992, 17419, 6416, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                               cast  \\\n",
       "0     19995  [{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...   \n",
       "1       285  [{\"cast_id\": 4, \"character\": \"Captain Jack Spa...   \n",
       "2    206647  [{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...   \n",
       "3     49026  [{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...   \n",
       "4     49529  [{\"cast_id\": 5, \"character\": \"John Carter\", \"c...   \n",
       "\n",
       "                                             cast_id  \n",
       "0  [397312, 32747, 1207263, 1180936, 1145098, 606...  \n",
       "1  [2603, 2440, 2441, 2449, 2450, 2452, 1430, 705...  \n",
       "2  [1168129, 578512, 1599254, 1599239, 1437333, 1...  \n",
       "3  [21505, 53252, 1188950, 1172491, 1343746, 7733...  \n",
       "4  [1721985, 62082, 17287, 1721992, 17419, 6416, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten()\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** Given the size of our dataset, we decided to keep only the cast members that played in at least 5 movies. Thus, we create a list containing the ids of these actors in order to filter the rest out from <i>cast_id</i>. After this, we generate the list of edges corresponding to our problem: all the actors which played in the same movie.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2231, 380, 62, 1892, 192, 884, 3896, 85, 887, 2963]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount = movies['cast_id'].apply(pd.Series).stack().value_counts()\n",
    "discount = list(discount[discount > 4].index.astype(int))\n",
    "discount[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3e141938c55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cast_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cast_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edges'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cast_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3196\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             return self._constructor(mapped,\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                     mgr = _arrays_to_mgr(arrays, columns, index, columns,\n\u001b[0;32m--> 400\u001b[0;31m                                          dtype=dtype)\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7321\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7323\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4871\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4872\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4873\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4874\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ObjectBlock'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4938\u001b[0;31m         \u001b[0mobject_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_simple_blockify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ObjectBlock'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4939\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_simple_blockify\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4974\u001b[0m     \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4975\u001b[0m     \"\"\"\n\u001b[0;32m-> 4976\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4978\u001b[0m     \u001b[0;31m# CHECK DTYPE?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SinanBursa/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   5037\u001b[0m     \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5038\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5039\u001b[0;31m         \u001b[0mstacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5041\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "movies['cast_id'] = movies['cast_id'].apply(lambda x: [y for y in x if y in discount])\n",
    "movies['edges'] = movies['cast_id'].apply(lambda x: list(itertools.combinations(x, 2)))\n",
    "edges = list(movies['edges'].apply(pd.Series).stack())\n",
    "edges[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** We noticed that some movies didn't have any ids in the <i>cast_id</i> anymore, meaning that all the actors that played in them played in less than $5$ movies. Thus, we simply decided to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_movies = set()\n",
    "\n",
    "for idx, movie in movies.iterrows():\n",
    "    if len(movie['edges']) == 0:\n",
    "        discarded_movies.add(movie['movie_id'])\n",
    "\n",
    "print(len(discarded_movies))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[~movies['movie_id'].isin(discarded_movies)]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** After creating the edge list, we create the features that will be useful later on. We decided to keep the <i>gender</i> and the <i>movies</i> an actor played in as the main features. However, we may enrich this list in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pd.DataFrame()\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for idx, film in movies.iterrows():\n",
    "    cast_df = pd.DataFrame(eval(movies['cast'][idx]))\n",
    "    cast_df['movies'] = idx\n",
    "    cast_df = cast_df.drop(['character','order','cast_id', 'credit_id'],axis = 1)  \n",
    "    \n",
    "    frames = [new_df, cast_df]\n",
    "    new_df = pd.concat(frames, join = 'outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes_df = new_df['movies'].groupby([new_df.gender, new_df.id, new_df.name]).apply(list).reset_index()\n",
    "nodes_df = nodes_df[nodes_df.id.isin(discount)]\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = nodes_df.set_index('id').drop('name', axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create the adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there are edges connecting the attributed nodes that you organized in the dataframe above. The connectivity of the network is captured by the adjacency matrix $W$. If $N$ is the number of nodes, the adjacency matrix is an $N \\times N$ matrix where the value of $W(i,j)$ is the weight of the edge connecting node $i$ to node $j$.  \n",
    "\n",
    "There are two possible scenarios for your adjacency matrix construction, as you already learned in the tutorial by Benjamin:\n",
    "\n",
    "1) The edges are given to you explicitly. In this case you should simply load the file containing the edge information and parse it in order to create your adjacency matrix. See how to do that in the  [graph from edge list]() demo.\n",
    "\n",
    "2) The edges are not given to you. In that case you will have to create a feature graph. In order to do that you will have to chose a distance that will quantify how similar two nodes are based on the values in their corresponding feature vectors. In the [graph from features]() demo Benjamin showed you how to build feature graphs when using Euclidean distances between feature vectors. Be curious and explore other distances as well! For instance, in the case of high-dimensional feature vectors, you might want to consider using the cosine distance. Once you compute the distances between your nodes you will have a fully connected network. Do not forget to sparsify by keeping the most important edges in your network.\n",
    "\n",
    "Follow the appropriate steps for the construction of the adjacency matrix of your network and provide it in the Numpy array ``adjacency`` below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** As we need a way to keep track of the ids of the cast members, we first create a DataFrame in order to construct our adjacency matrix. The <i>discount</i> list (exhaustive list of the nodes) will be used as a mapping between the nodes and the adjacency matrix; meaning their index in the matrix is simply their index in the <i>discount</i> list.\n",
    "\n",
    "After this, we simply convert the adjacency matrix to a Numpy array and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = pd.DataFrame(np.zeros(shape=(len(discount),len(discount))), columns=discount, index=discount)\n",
    "for e1, e2 in edges:\n",
    "    if e1 in discount and e2 in discount:\n",
    "        adj.at[e1, e2] += 1\n",
    "        adj.at[e2, e1] += 1\n",
    "    else:\n",
    "        edges.remove((e1,e2))\n",
    "adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = adj.values\n",
    "adj_max = adjacency.max()\n",
    "adjacency = np.vectorize(lambda x: x/adj_max)(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = len(discount)\n",
    "n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to plot the (weighted) adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(adjacency, markersize=0.005)\n",
    "plt.title('adjacency matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** As we can see in this plot, the first actors are much more connected then the last actors. This results could be explained by the fact that our adjacency matrix is in a decreasing order of number of movies played. So the first rows contain the actors that played in most movies and the last rows contain the actors that played in the least amount of movies. As such, it is expected that the actors that played in the most are statistically the ones that will be the most connected to other actors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the maximum number of links $L_{max}$ in a network with $N$ nodes (where $N$ is the number of nodes in your network)? How many links $L$ are there in your collected network? Comment on the sparsity of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max = n_nodes*(n_nodes-1)/2\n",
    "print(L_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max / len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes * math.sqrt(n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have that the network is not fully connected, yet not sparse. Indeed, we have that $L=O(n*\\sqrt{n})$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Is your graph directed or undirected? If it is directed, convert it to an undirected graph by symmetrizing the adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make a matrix symmetric, we sum the original matrix with its transpose and divide the result by 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = (adjacency + adjacency.T)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In the cell below save the features dataframe and the **symmetrized** adjacency matrix. You can use the Pandas ``to_csv`` to save the ``features`` and Numpy's ``save`` to save the ``adjacency``. We will reuse those in the following milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/adj.npy\", adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Are the edges of your graph weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yes, the edges are weighted and the weights correspond to the number of movies where actors played together.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the degree distibution of your network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.count_nonzero(adjacency, axis=1)\n",
    "\n",
    "assert len(degree) == n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see the histogram of the degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(degree) / float(n_nodes)\n",
    "plt.hist(degree, weights=weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(degree)/n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Comment on the degree distribution of your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The degree distribution of the graph seems large but is not unexpected. Indeed, the number of actors in a movie is $8$ on average, while the number of movies an actor played in is $10$ in average. The order of magnitude seems to be corresponding according to the rule of thumb.<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of a graph and determines whether the graph is connected or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** In order to decide if our network is connected or not, we start from the index zero of the adjacency matrix and store the indices of the connected nodes step by step into a set called 'visited'. Then we compare the number of the nodes with the number of elements in the 'visited' set to see if the whole graph is connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_graph(adjacency):\n",
    "    #in visited and queue, we store the indices of columns/rows\n",
    "    visited, queue = set(), [0]\n",
    "    while queue:\n",
    "        index = queue.pop(0)\n",
    "        if index not in visited:\n",
    "            visited.add(index)\n",
    "            actor_connected_to = set(np.nonzero(adjacency[index])[0])\n",
    "            queue.extend(actor_connected_to - visited)\n",
    "            \n",
    "    if len(visited) == len(adjacency):\n",
    "        connected = True\n",
    "    else:\n",
    "        connected = False\n",
    "    \n",
    "    return connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your graph connected? Run the ``connected_graph`` function to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(connected_graph(adjacency)):\n",
    "    print('Our graph is connected')\n",
    "else:\n",
    "    print('Our graph is not connected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Write a function that extracts the connected components of a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** Firstly, we find the connected nodes starting from the index zero of adjacency matrix and store the first connected component in a list called 'component_list'. Meanwhile, we store the indices of the unconnected nodes in a set called 'not_visited' and loop again for adding a new connected component into 'component_list' starting with the indices in 'not_visited' until 'not_visited' is empty. We return all the connected components as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_components(adjacency):\n",
    "    not_visited = []\n",
    "    for i in range(len(adjacency)):\n",
    "        not_visited.append(i)\n",
    "    #Before starting the while loop, not_visited is containing all the nodes (row indices in the adjacency matrix)\n",
    "    \n",
    "    component_list = list() #This list is created in order to contain the components\n",
    "    while not_visited:\n",
    "        queue = [not_visited[0]]\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            index = queue.pop(0)\n",
    "            if index not in visited:\n",
    "                visited.add(index)\n",
    "                actor_connected_to = set(np.nonzero(adjacency[index])[0])\n",
    "                queue.extend(actor_connected_to - set(visited))\n",
    "                \n",
    "        not_visited = list(set(not_visited) - visited)\n",
    "        component_list.append(list(visited)) \n",
    "    \n",
    "    components = []\n",
    "    for idx, value in enumerate(component_list):\n",
    "        comp_adj = np.take(adjacency, component_list[idx], axis = 0)\n",
    "        comp_adj = np.take(comp_adj, component_list[idx], axis = 1)\n",
    "        components.append(comp_adj)\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components is your network composed of? What is the size of the largest connected component? Run the ``find_components`` function to determine your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_adjacency = find_components(adjacency)\n",
    "print('Our network is composed of', len(components_adjacency), 'connected components.\\n')\n",
    "print('The size of the largest connected component is ', len(components_adjacency[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Write a function that takes as input the adjacency matrix and a node (`source`) and returns the length of the shortest path between that node and all nodes in the graph using Dijkstra's algorithm. **For the purposes of this assignment we are interested in the hop distance between nodes, not in the sum of weights. **\n",
    "\n",
    "Hint: You might want to mask the adjacency matrix in the function ``compute_shortest_path_lengths`` in order to make sure you obtain a binary adjacency matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** As inputs, this function takes the adjavency matrix and a index as the starting node. This source node in question is tagged as 0 (hop_distance), then all the nodes directly connected to this source node is tagged as 1, the ones that are connected to nodes with tag 1 are tagged with 2 and so on until all the connected graph is tagged. The unconnected nodes are tagged as 'inf' since the distance of them to the connected graph is infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_path_lengths(adjacency, source):\n",
    "    \n",
    "    shortest_path_lengths = np.full(len(adjacency), np.inf, dtype=float)\n",
    "    visited, queue = set(), [source]\n",
    "    hop_distance = 0\n",
    "    queue2 = list()\n",
    "    while queue:\n",
    "        index = queue.pop(0)\n",
    "        if index not in visited:\n",
    "            visited.add(index)\n",
    "            shortest_path_lengths[index] = hop_distance\n",
    "            actor_connected_to = set(np.nonzero(adjacency[index])[0])\n",
    "            queue2.extend(actor_connected_to - visited)\n",
    "        if not queue:\n",
    "            hop_distance = hop_distance + 1\n",
    "            queue.extend(queue2)\n",
    "            queue2 = list()    \n",
    "    return shortest_path_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "The diameter of the graph is the length of the longest shortest path between any pair of nodes. Use the above developed function to compute the diameter of the graph (or the diameter of the largest connected component of the graph if the graph is not connected). If your graph (or largest connected component) is very large, computing the diameter will take very long. In that case downsample your graph so that it has 1.000 nodes. There are many ways to reduce the size of a graph. For the purposes of this milestone you can chose to randomly select 1.000 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** We have randomly selected 1000 indices/nodes from the adjacency matrix and created a new adjacency matrix (graph) with these 1000 nodes. Then we check if this new adjacency matrix is a connected graph or not. In case if the graph is not connected, we take the connected components of this new graph and calculate the diameter of the largest component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "random_source_list = np.random.randint(0,n_nodes,size=sample_size)\n",
    "\n",
    "adjacency_random = np.take(adjacency, random_source_list, axis=0)\n",
    "adjacency_random = np.take(adjacency_random, random_source_list, axis=1)\n",
    "\n",
    "print()\n",
    "\n",
    "print('For downsampling of actors data, we find', len(find_components(adjacency_random)), 'connected components in our new random graph')\n",
    "\n",
    "max_length_list = []\n",
    "\n",
    "for source in range(sample_size):\n",
    "    max_length_list.append(max(compute_shortest_path_lengths(adjacency_random, source)))\n",
    "max_length = max(max_length_list)   \n",
    "\n",
    "if(connected_graph(adjacency_random)):\n",
    "    print('Our randomly downsampled network is connected')\n",
    "else:\n",
    "    print('Our randomly downsampled network is not connected')\n",
    "\n",
    "print('The diameter of whole randomly downsampled data is:', max_length)\n",
    "\n",
    "components = find_components(adjacency_random)   \n",
    "number_of_components = len(components)    \n",
    "if number_of_components > 1: #If downsampled graph is not connected\n",
    "    component_length_list = []\n",
    "    for i in range(number_of_components):\n",
    "        component_length_list.append(len(components[i]))\n",
    "    \n",
    "    length_array = np.array(component_length_list)\n",
    "    index_largest_component = np.argmax(length_array)\n",
    "    \n",
    "    adjacency_random_connected = components[index_largest_component]\n",
    "    \n",
    "    max_length_list = []\n",
    "    for source in range(len(adjacency_random_connected)):\n",
    "        max_length_list.append(max(compute_shortest_path_lengths(adjacency_random_connected, source)))\n",
    "    max_length = max(max_length_list)   \n",
    "\n",
    "    print('The diameter of the largest connected component of our randomly downsampled network is: ', max_length)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write a function that takes as input the adjacency matrix, a path length, and two nodes (`source` and `target`), and returns the number of paths of the given length between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** In this segment, we try to find the number of paths of given length. We form a new unweighted adjacency matrix by assigning 1 if two nodes are connected and 0 if the nodes are not connected (in this case we call it adjacency_non_weighted). Then according to the theorem seen in the chapter of \"GraphTheoryBasics\", we compute the number of n paths between two nodes by multiplying the adjacency matrix n times with itself (n given as the desired path length). Therefore we obtain a matrix where the value in index i,j is the number of paths with length n that are connecting node i and j. In our case i can be the source and j the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_paths(adjacency, source, target, length):\n",
    "    \n",
    "    adjacency_non_weighted = adjacency.copy()\n",
    "    adjacency_non_weighted[adjacency_non_weighted > 0] = 1\n",
    "    adjacency_non_weighted = np.asmatrix(adjacency_non_weighted)\n",
    "    \n",
    "    matrix_path_lengths = adjacency_non_weighted**length\n",
    "    n_paths = matrix_path_lengths[source, target]\n",
    "  \n",
    "    return n_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function on 5 pairs of nodes, with different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_paths(adjacency, 0, 10, 1))\n",
    "print(compute_paths(adjacency, 0, 10, 2))\n",
    "print(compute_paths(adjacency, 0, 10, 3))\n",
    "print(compute_paths(adjacency, 23, 67, 2))\n",
    "print(compute_paths(adjacency, 15, 93, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "How many paths of length 3 are there in your graph? Hint: calling the `compute_paths` function on every pair of node is not an efficient way to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** In order to find out how many paths of length 3 there are, we start by taking the adjacency matrix (in our case adjacency_non_weighted). As seen in previous question the paths with length 3 can be found by multiplying the adjacency matrix 3 times by itself. As our matrix is symmetric, it contains the same path information twice. So the number of paths between i and j is the same for j and i. As such we remove all values below the diagonal in order to have an upper triangular matrix. Then we take the sum of the values in the matrix which gives us the total number of paths with length 3.\n",
    "In our case we decided to keep the diagonal values. These values give us the number of path with length 3 that connects the same actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_non_weighted = adjacency\n",
    "adjacency_non_weighted[adjacency_non_weighted > 0] = 1\n",
    "adjacency_non_weighted = np.asmatrix(adjacency_non_weighted)\n",
    "matrix_path_lengths = adjacency_non_weighted**3\n",
    "upper_tri = np.triu(matrix_path_lengths, 0)\n",
    "np.sum(upper_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of your graph (or of the largest connected component of your graph) and a node and returns the clustering coefficient of that node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This algorithm simply roams through the list of neighbors of <i>node</i> in order to determine any links between them. The <i>visited</i> set allows us to keep track of the nodes that were already taken into account (which is why we keep the $2$ at the beginning of the final formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clustering_coefficient(adjacency, node):\n",
    "    \"\"\"Compute the clustering coefficient of a node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    node: int\n",
    "        The node whose clustering coefficient will be computed. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The clustering coefficient of the node. A number between 0 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    visited = set()\n",
    "    neighbors = set(np.nonzero(adjacency[node])[0])\n",
    "    \n",
    "    if len(neighbors) == 0 or len(neighbors) == 1:\n",
    "        return 0\n",
    "    \n",
    "    links = 0\n",
    "    \n",
    "    for u in neighbors:\n",
    "        visited.add(u)\n",
    "        nonzero = set(np.nonzero(adjacency[u])[0]) - set([node])\n",
    "        for v in (neighbors - visited):\n",
    "            if v in nonzero:\n",
    "                links += 1\n",
    "    \n",
    "    clustering_coefficient = (2*links)/(len(neighbors)*(len(neighbors)-1))\n",
    "    \n",
    "    return clustering_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_clustering_coefficient(adjacency, 3669)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the average clustering coefficient of your graph (or of the largest connected component of your graph if your graph is disconnected)? Use the function ``compute_clustering_coefficient`` to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_coefficient = 0\n",
    "\n",
    "for node in range(n_nodes):\n",
    "    avg_coefficient += compute_clustering_coefficient(adjacency, node)\n",
    "    \n",
    "avg_coefficient = avg_coefficient/n_nodes\n",
    "print(avg_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** We have that the average clustering coefficient is around $0.22$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
